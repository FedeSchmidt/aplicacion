[
	{
		"mnist": "El dataset MNIST es un conjunto de imágenes de dígitos escritos a mano que se usa comunmente en el entrenamiento de diversos sistemas que procesen imágenes, como así también en el entrenamiento y testing de sistemas de machine learning.\nEl conjunto contiene 70.000 imágenes, de las cuales en general se destinan 60.000 para entrenamiento y las restantes 10.000 como conjunto de test.\nUna base de datos extendida de MNIST, llamada EMNIST, se publicó en 2017, conteniendo en total 280.000 imágenes.",
		"learning_rate": "El learning ratio es un parámetro real, configurable, que influirá en la minimización de los errores cometidos por la red en su entrenamiento, y por tanto en la precisión y velocidad del mismo.",
		"ciclos": "Las cantidad ciclos indica las veces que la red debe procesar de forma completa el conjunto de entrenamiento.",
		"metric": "La métrica es una función que permite verificar el error general cometido al entrenar y evaluar la evolución de la red.",
		"cost_function": "La función de costo da el error cometido por la red al procesar el conjunto de entrenamiento.\nA través de la configuración de los demás parámetros, lo que se busca es hallar un mínimo para esta función, es decir lograr el menor error posible.",
		"batch_size": "Este parámetro permite dividir el conjunto de entrenamiento en partes. Por defecto, para el problema de MNIST, si no se ha configurado se toma un batch de 32 elementos.\nSe puede poner el valor que se desee, pero se prefieren valores no muy grandes.",
		"estructura": "Una red neuronal artificial es un grafo dirigido, donde los nodos son neuronas artificiales y están conectados por arcos.\nCada nodo recibe valores de los arcos entrantes, computa un valor según la función de activación de esa neurona, y emite ese valor por sus arcos salientes.\nLas neuronas se agrupan en capas, y se pueden distinguir tres tipos de grupos: la capa de entrada, las capas ocultas y la capa de salida.",
		"activacion": "La función de activación permitirá a una neurona artificial convertir las entradas en sus nuevas salidas. Cada función tiene beneficios y desventajas en cuanto a la precisión y la velocidad del aprendizaje.\nLa neurona más básica se denomina perceptrón, que emite como salida solo 0 y 1, y neuronas más útiles son las Sigmoides, ReLU, Lineales y Softmax.\nRespecto a la función Softmax, una neurona de este tipo emite resultados realizando una distribución de probabilidades, con lo cual solo se utiliza en la capa de salida de la red.",
		"construccion": "Para la construcción de una red neuronal artificial, la capa de entrada se configura de acuerdo al formato de los datos que se tengan en el dataset.\nLa capa de salida, por su parte, también depende del problema y su configuración depende de la forma en que se desee que la red emita sus resultados.\nFinalmente, las capas ocultas se configuran de forma más experimental, realizando modificaciones y buscando los mejores resultados posibles, ya que no existe aún mucha teoría que permita configurarlas con la seguridad de que esa configuración va a resultar exitosa."
	}
]
